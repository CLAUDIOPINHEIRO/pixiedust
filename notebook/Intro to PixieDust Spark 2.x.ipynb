{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello PixieDust!\n",
    "This sample notebook provides you with an introduction to many features included in PixieDust. You can find more information about PixieDust at https://ibm-cds-labs.github.io/pixiedust/. To ensure you are running the latest version of PixieDust uncomment and run the following cell. Do not run this cell if you installed PixieDust locally from source and want to continue to run PixieDust from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import PixieDust\n",
    "Run the following cell to import the PixieDust library. You may need to restart your kernel after importing. Follow the instructions, if any, after running the cell. Note: You must import PixieDust every time you restart your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable the Spark Progress Monitor\n",
    "PixieDust includes a Spark Progress Monitor bar that lets you track the status of your Spark jobs. You can find more info at https://ibm-cds-labs.github.io/pixiedust/sparkmonitor.html. Note: there is a known issue with the Spark Progress Monitor on Spark 2.1. Run the following cell to enable the Spark Progress Monitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixiedust.enableJobMonitor();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use of the PackageManager\n",
    "You can use the PackageManager component of Pixiedust to install and uninstall maven packages into your notebook kernel without editing configuration files. This component is essential when you run notebooks from a hosted cloud environment and do not have access to the configuration files. You can find more info at https://ibm-cds-labs.github.io/pixiedust/packagemanager.html. Run the following cell to install the GraphFrame package. You may need to restart your kernel after installing new packages. Follow the instructions, if any, after running the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixiedust.installPackage(\"graphframes:graphframes:0.1.0-spark1.6\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to print out all installed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixiedust.printAllPackages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use of the display() API\n",
    "PixieDust lets you visualize your data in just a few clicks using the display() API. You can find more info at https://ibm-cds-labs.github.io/pixiedust/displayapi.html. The following cell creates a DataFrame and uses the display() API to create a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "charttype": "grouped",
      "clusterby": "year",
      "handlerId": "barChart",
      "keyFields": "zone",
      "rendererId": "bokeh",
      "rowCount": "100",
      "showLegend": "true",
      "stacked": "false",
      "staticFigure": "false",
      "title": "Simple Bar Chart",
      "valueFields": "unique_customers"
     }
    }
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.getOrCreate()\n",
    "d1 = sparkSession.createDataFrame(\n",
    "[(2010, 'Camping Equipment', 3),\n",
    " (2010, 'Golf Equipment', 1),\n",
    " (2010, 'Mountaineering Equipment', 1),\n",
    " (2010, 'Outdoor Protection', 2),\n",
    " (2010, 'Personal Accessories', 2),\n",
    " (2011, 'Camping Equipment', 4),\n",
    " (2011, 'Golf Equipment', 5),\n",
    " (2011, 'Mountaineering Equipment',2),\n",
    " (2011, 'Outdoor Protection', 4),\n",
    " (2011, 'Personal Accessories', 2),\n",
    " (2012, 'Camping Equipment', 5),\n",
    " (2012, 'Golf Equipment', 5),\n",
    " (2012, 'Mountaineering Equipment', 3),\n",
    " (2012, 'Outdoor Protection', 5),\n",
    " (2012, 'Personal Accessories', 3),\n",
    " (2013, 'Camping Equipment', 8),\n",
    " (2013, 'Golf Equipment', 5),\n",
    " (2013, 'Mountaineering Equipment', 3),\n",
    " (2013, 'Outdoor Protection', 8),\n",
    " (2013, 'Personal Accessories', 4)],\n",
    "[\"year\",\"zone\",\"unique_customers\"])\n",
    "\n",
    "display(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use of the Scala bridge\n",
    "Data scientists working with Spark may occasionaly need to call out to one of the hundreds of libraries available on spark-packages.org which are written in Scala or Java. PixieDust provides a solution to this problem by letting users directly write and run scala code in its own cell. It also lets variables be shared between Python and Scala and vice-versa. You can find more info at https://ibm-cds-labs.github.io/pixiedust/scalabridge.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a python variable that we'll use in scala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "python_var = \"Hello From Python\"\n",
    "python_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create scala code that use the python_var and create a new variable that we'll use in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%scala\n",
    "println(python_var)\n",
    "println(python_num+10)\n",
    "val __scala_var = \"Hello From Scala\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the __scala_var from python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__scala_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sample Data\n",
    "PixieDust includes a number of sample data sets. You can use these sample data sets to start playing with the display() API and other PixieDust features. You can find more info at https://ibm-cds-labs.github.io/pixiedust/loaddata.html. Run the following cell to view the available data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixiedust.sampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use of sample data\n",
    "To use sample data locally run the following cell to install required packages. You may need to restart your kernel after running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixiedust.installPackage(\"com.databricks:spark-csv_2.10:1.5.0\")\n",
    "pixiedust.installPackage(\"org.apache.commons:commons-csv:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get the first data set from the list. This will return a DataFrame and assign it to the variable d2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = pixiedust.sampleData(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the sample data set (d2) into the display() API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also download data from a CSV file into a DataFrame which you can use with the display() API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d3 = pixiedust.sampleData(\"https://openobjectstore.mybluemix.net/misc/milliondollarhomes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PixieDust Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% pixiedustLog -l debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Info.\n",
    "The following cells will print out information related to your notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%scala\n",
    "val __scala_version = util.Properties.versionNumberString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "print('PYTHON VERSON = ' + platform.python_version())\n",
    "print('SPARK VERSON = ' + sc.version)\n",
    "print('SCALA VERSON = ' + __scala_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Info.\n",
    "For more information about PixieDust check out the following:\n",
    "#### PixieDust Documentation: https://ibm-cds-labs.github.io/pixiedust/index.html\n",
    "#### PixieDust GitHub Repo: https://github.com/ibm-cds-labs/pixiedust"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.0)",
   "language": "python",
   "name": "pythonwithpixiedustspark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
